---
title: "lab8"
author: "Gabrielle"
date: '2022-11-14'
output: 
  html_document:
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, results = FALSE)
library(tidyverse)
library(here)
library(ggpubr)
library(janitor)
library(broom)
library(knitr)
```

# lab 8: dummy variables, tables, and model selection using BIC

### load in the data
```{r}
penguins <- read_csv(here("data", "penguins.csv"))
```


### examples of pairs() and cor()
```{r, results = TRUE}
penguins_mod <- penguins %>% 
  select(bill_length_mm, bill_depth_mm, flipper_length_mm, body_mass_g) %>% 
  drop_na()
# selecting the continuous variables, and not the discrete ones, because correlation wouldn't look right for discrete variables

pairs(penguins_mod)
cor(penguins_mod)
```

## Linear models
```{r}
# new data set
penguins_Adelie_Torgersen <- penguins %>% 
  filter(species == "Adelie") %>% 
  filter(island == "Torgersen") %>% 
  drop_na()
```

## models
```{r}
model_0 <- lm(body_mass_g ~ 1, data = penguins_Adelie_Torgersen)
# a regression without anything in "x" it's the mean of the variable y

model_1 <- lm(body_mass_g ~ flipper_length_mm, data = penguins_Adelie_Torgersen)
# body mass is a function of flipper length

model_2 <- lm(body_mass_g ~ sex, data = penguins_Adelie_Torgersen)
# body mass is a function of sex

model_3 <- lm(body_mass_g ~ flipper_length_mm + sex, data = penguins_Adelie_Torgersen)
# body mass is a function of flipper length coupled with the sex



## model outputs saved to data

model_0_out <- summary(model_0)

model_1_out <- summary(model_1)

model_2_out <- summary(model_2)

model_3_out <- summary(model_3)

### now we can start using the model results and make data tables

```


Model 0 This null model captures the idea that there is no explanatory power of flipper length or sex. It is useful for comparison to other models with more complexity.

Model 1 This model is a simple linear regression.

Model 2 This model with only a dummy variable for sex.

Model 3 This model with a dummy variable for sex and a continuous variable of flipper length.


**Model 0**
```{r, results = TRUE}
out_0_tidy <- tidy(model_0)
out_0_tidy
# 'straw man stupid test'... is the penguin mass different than zero... well yes, of course it is

out_0_glance <- glance(model_0)
out_0_glance
# r squared is zero because there is only one variable
# sigma, variance of the residuals
# we're not testing a regression model, so many of the results are NA
# there is a model being run, so you can see the logLik and AIC and BIC

kable(out_0_tidy, format = "markdown", digits = 3, caption = "Tests of linear model (model 0) coefficients")

kable(out_0_glance, format = "markdown", digits = 3, caption = "Tests of linear model (model 0)")

```


**Model 1**
```{r, results = TRUE}
out_1_tidy <- tidy(model_1)
out_1_tidy

out_1_glance <- glance(model_1)
out_1_glance

kable(out_1_tidy, format = "markdown", digits = 3, caption = "Tests of linear model (model 1) coefficients")

kable(out_1_glance, format = "markdown", digits = 3, caption = "Tests of linear model (model 1)")

# the intercept is nonsensical
# including the intercept didn't add much to our interpretation
# we can only make an inference for the data range we have
```



**Model 2**
```{r, results = TRUE}
out_2_tidy <- tidy(model_2)
out_2_tidy

out_2_glance <- glance(model_2)
out_2_glance

kable(out_2_tidy, format = "markdown", digits = 3, caption = "Tests of linear model (model 2) coefficients")
# this is essentially a t-test

kable(out_2_glance, format = "markdown", digits = 3, caption = "Tests of linear model (model 2)")

```

note the lower BIC than model_1, which is telling us that clearly add sex to the model tells us something

An aside How does model 2 compare to a two sample t-test? Look at the t values and p values of the t test and the dummy variable “sexmale” output with lm(). Punchline, two sample t-tests can be a model within a suite of linear models by using dummy variable (two factors, i.e. males or females). With more factors (2+) and the use of dummy variables, we can do ANOVA.

```{r}
#t-test code

male <- penguins_Adelie_Torgersen %>% 
  filter(sex=="male")

male <- male$body_mass_g

female <- penguins_Adelie_Torgersen %>% 
  filter(sex=="female")

female <- female$body_mass_g

t.test(male,female,var.equal = TRUE)
```



**Model 3**
```{r, results = TRUE}
out_3_tidy <- tidy(model_3)
out_3_tidy

out_3_glance <- glance(model_3)
out_3_glance

kable(out_3_tidy, format = "markdown", digits = 3, caption = "Tests of linear model (model 3) coefficients")

kable(out_3_glance, format = "markdown", digits = 3, caption = "Tests of linear model (model 3)")


```


### model 2 appears to be the best model
delta BIC of about 4 is a weak indication; they're doing about the same job; flipper length isn't telling us much; might just want to use the variable sex

conclusion: the variation in the body mass is driven by sex


## Example of Model Selection
Another approach to choosing the “best model” is using information criteria. Here we will use the BIC (The Bayesian Information Criteria) also known as the SIC as it should not be confused with Bayesian Statistics. The BIC is robust and has better error properties than the AIC, The Akaike’s Information Criteria, a very popular and commonly applied model selection function. However, see this recent publication for why BIC should be used over AIC here.

The BIC is:

SIC=ln(n)∗k−2∗ln(L)

where, n is the number of observations, k is the number of parameters, and L is the likelihood. All of these values can be pulled from the model statistics in the lm() output.

Condensing the tables // pull out the BIC values into a table to make them readable

```{r}
# We can call the BIC directly or as a list of models like this:
BIC_list <- c(BIC(model_0), BIC(model_1), BIC(model_2), BIC(model_3))
BIC_list
```

## A method using data.frame

```{r, results = TRUE}
# we may want to merge data and select only certain model statistics. 
# here is a way to manipulate the data to get a table

model_output <- rbind(data.frame(glance(model_0)),data.frame(glance(model_1)),data.frame(glance(model_2)),data.frame(glance(model_3))) %>% 
  select(adj.r.squared, BIC)

model_output

model_output_1 <- mutate(model_output, delta.BIC = BIC-min(BIC_list))

model_output_1

# add a column that labels each model within the table!
model_output_1$model <- c("Model 0", "Model 1", "Model 2", "Model 3")

model_output_1

# rearrange the order of the columns
model_output_1 <- model_output_1[,c("model", "adj.r.squared", "BIC", "delta.BIC")]
model_output_1

# even though adj.r.squared is a frequentist term, it is still informative
# here, you can see that the r squared on model 2 and model 3 are really similar

kable(model_output_1, format = "markdown", digits = 3, caption = "R-Squared Adjusted, BIC, and delta BIC for the penguin models. Delta BIC >7 indicates models that should be dismissed from further consideration.")
```
Model 2 is clearly the best, but model 3 is also performing okay. Model 0 and model 1 can be thrown out



